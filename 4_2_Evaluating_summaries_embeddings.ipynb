{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peremartra/Apress_LLProjects_Book/blob/main/4-Evaluating%20LLMs/4_2_Evaluating_summaries_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "a1a5ae21-8eaf-431c-bb2f-22a8dc8b7e47",
      "metadata": {
        "id": "a1a5ae21-8eaf-431c-bb2f-22a8dc8b7e47"
      },
      "outputs": [],
      "source": [
        "#Loading Necessary Libraries\n",
        "!pip install -q langchain==0.1.7\n",
        "!pip install -q langchain-openai==0.0.6\n",
        "!pip install -q langchainhub==0.1.14\n",
        "!pip install -q datasets==2.17.0\n",
        "!pip install -q huggingface-hub==0.20.3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c2f8fcc-0d7f-422b-8d23-6e2e70a7c4a5",
      "metadata": {
        "id": "6c2f8fcc-0d7f-422b-8d23-6e2e70a7c4a5"
      },
      "source": [
        "<div>\n",
        "    <h1>Large Language Models Projects</a></h1>\n",
        "    <h3>Apply and Implement Strategies for Large Language Models</h3>\n",
        "    <h2>4.2-Tracing and Evaluating LLMs with LangSmith.</h2>\n",
        "    <h3>Evaluating summaries using embedding distance</h3>\n",
        "    <p>by <b>Pere Martra</b></p>\n",
        "</div>\n",
        "\n",
        "Previously in the notebook, [Rouge Metrics: Evaluating Summaries](https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/4-Evaluating%20LLMs/rouge-evaluation-untrained-vs-trained-llm.ipynb), we learned how to use ROUGE to evaluate which summary best approximated the one created by a human. This time, we will use embedding distance and LangSmith to verify which model produces summaries more similar to the reference ones.\n",
        "\n",
        "We will continue using the same dataset and models as in the example with ROUGE. That is, a dataset containing CNN news articles and their human-created summaries, which will be taken as the reference. Additionally, we have two T5 models, with one of them fine-tuned specifically for generating summaries.\n",
        "\n",
        "__________\n",
        "\n",
        " If you want to run this notebook, you will need to have API keys from OpenAI, HuggingFace, and LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "6db4887a-a214-49bc-9bb6-0ae59c1092ec",
      "metadata": {
        "id": "6db4887a-a214-49bc-9bb6-0ae59c1092ec"
      },
      "outputs": [],
      "source": [
        "#You need a LangChain API Key.\n",
        "from getpass import getpass\n",
        "import os\n",
        "if not 'LANGCHAIN_API_KEY' in os.environ:\n",
        "  os.environ[\"LANGCHAIN_API_KEY\"] = getpass(\"LangChain API Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass(\"LangChain API Key: \")"
      ],
      "metadata": {
        "id": "qi7KSvxYgVis",
        "outputId": "826f1514-0e6e-4971-d34c-bf6294f097f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qi7KSvxYgVis",
      "execution_count": 51,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangChain API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "ca8e338c-45e2-42d1-94f2-64b70cc4b529",
      "metadata": {
        "id": "ca8e338c-45e2-42d1-94f2-64b70cc4b529"
      },
      "outputs": [],
      "source": [
        "if not 'OPENAI_API_KEY' in os.environ:\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"OPENAI API Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "5f4adff9-1169-4173-a72b-c983dcb6160d",
      "metadata": {
        "id": "5f4adff9-1169-4173-a72b-c983dcb6160d"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
        "#os.environ[\"LANGCHAIN_PROJECT\"]=\"langsmith_yttest01\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "0189af0e-8145-407b-a32d-2f21ac0ca5ff",
      "metadata": {
        "id": "0189af0e-8145-407b-a32d-2f21ac0ca5ff"
      },
      "outputs": [],
      "source": [
        "#Importing Client from Langsmith\n",
        "from langsmith import Client\n",
        "client = Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e7c4be2-fdae-42cf-b1b2-9aef89081ad2",
      "metadata": {
        "id": "4e7c4be2-fdae-42cf-b1b2-9aef89081ad2"
      },
      "source": [
        "## Create Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "dbc219ae-1760-4f3d-92e6-aaeb6fb7ee9f",
      "metadata": {
        "id": "dbc219ae-1760-4f3d-92e6-aaeb6fb7ee9f"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "cnn_dataset = load_dataset(\n",
        "    \"ccdv/cnn_dailymail\", version\n",
        "    =\"3.0.0\",\n",
        "    trust_remote_code=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "7684f9ef-f665-42c1-ac89-f2726f7ae0da",
      "metadata": {
        "id": "7684f9ef-f665-42c1-ac89-f2726f7ae0da"
      },
      "outputs": [],
      "source": [
        "def add_prefix(example):\n",
        "    return {\n",
        "        **example,\n",
        "        \"article\": f\"Summarize this news:\\n{example['article']}\"\n",
        "    }\n",
        "\n",
        "#cnn_dataset = cnn_dataset.map(add_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "3fc26871-68d9-4ab1-a9c9-b6caf241d636",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fc26871-68d9-4ab1-a9c9-b6caf241d636",
        "outputId": "7e7d56bb-3134-4317-873e-ed02cf8b5258"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['article', 'highlights', 'id'],\n",
              "    num_rows: 3\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "#Get just a few news to test\n",
        "MAX_NEWS=3\n",
        "sample_cnn = cnn_dataset[\"test\"].select(range(MAX_NEWS)).map(add_prefix)\n",
        "\n",
        "sample_cnn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc0ef576-ea25-446d-a99b-354678a274ba",
      "metadata": {
        "id": "bc0ef576-ea25-446d-a99b-354678a274ba"
      },
      "source": [
        "The dataset contains three columns: article, highlights, and id. To use LangSmith, we need to create a dataset in LangSmith format.\n",
        "\n",
        "LangSmith expects a prompt and a result. To achieve this, we will transform the article into a prompt by adding the prefix: \"Summarize this news.\" As a result, we will use the content of highlights, which represents the summaries created by humans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "4e3cea3a-fde5-4e52-90f9-d1db4fd30bc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e3cea3a-fde5-4e52-90f9-d1db4fd30bc2",
        "outputId": "f643eaab-aad1-4be2-d0ae-f467930b83f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'article': 'Summarize this news:\\n(CNN)James Best, best known for his portrayal of bumbling sheriff Rosco P. Coltrane on TV\\'s \"The Dukes of Hazzard,\" died Monday after a brief illness. He was 88. Best died in hospice in Hickory, North Carolina, of complications from pneumonia, said Steve Latshaw, a longtime friend and Hollywood colleague. Although he\\'d been a busy actor for decades in theater and in Hollywood, Best didn\\'t become famous until 1979, when \"The Dukes of Hazzard\\'s\" cornpone charms began beaming into millions of American homes almost every Friday night. For seven seasons, Best\\'s Rosco P. Coltrane chased the moonshine-running Duke boys back and forth across the back roads of fictitious Hazzard County, Georgia, although his \"hot pursuit\" usually ended with him crashing his patrol car. Although Rosco was slow-witted and corrupt, Best gave him a childlike enthusiasm that got laughs and made him endearing. His character became known for his distinctive \"kew-kew-kew\" chuckle and for goofy catchphrases such as \"cuff \\'em and stuff \\'em!\" upon making an arrest. Among the most popular shows on TV in the early \\'80s, \"The Dukes of Hazzard\" ran until 1985 and spawned TV movies, an animated series and video games. Several of Best\\'s \"Hazzard\" co-stars paid tribute to the late actor on social media. \"I laughed and learned more from Jimmie in one hour than from anyone else in a whole year,\" co-star John Schneider, who played Bo Duke, said on Twitter. \"Give Uncle Jesse my love when you see him dear friend.\" \"Jimmy Best was the most constantly creative person I have ever known,\" said Ben Jones, who played mechanic Cooter on the show, in a Facebook post. \"Every minute of his long life was spent acting, writing, producing, painting, teaching, fishing, or involved in another of his life\\'s many passions.\" Born Jewel Guy on July 26, 1926, in Powderly, Kentucky, Best was orphaned at 3 and adopted by Armen and Essa Best, who renamed him James and raised him in rural Indiana. Best served in the Army during World War II before launching his acting career. In the 1950s and 1960s, he accumulated scores of credits, playing a range of colorful supporting characters in such TV shows as \"The Twilight Zone,\" \"Bonanza,\" \"The Andy Griffith Show\" and \"Gunsmoke.\" He later appeared in a handful of Burt Reynolds\\' movies, including \"Hooper\" and \"The End.\" But Best will always be best known for his \"Hazzard\" role, which lives on in reruns. \"Jimmie was my teacher, mentor, close friend and collaborator for 26 years,\" Latshaw said. \"I directed two of his feature films, including the recent \\'Return of the Killer Shrews,\\' a sequel he co-wrote and was quite proud of as he had made the first one more than 50 years earlier.\" People we\\'ve lost in 2015 . CNN\\'s Stella Chan contributed to this story.', 'highlights': 'James Best, who played the sheriff on \"The Dukes of Hazzard,\" died Monday at 88 .\\n\"Hazzard\" ran from 1979 to 1985 and was among the most popular shows on TV .', 'id': '00200e794fa41d3f7ce92cbf43e9fd4cd652bb09'}\n"
          ]
        }
      ],
      "source": [
        "print(sample_cnn[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1051e780-8871-4fd4-9e18-68ad8bc837f8",
      "metadata": {
        "id": "1051e780-8871-4fd4-9e18-68ad8bc837f8"
      },
      "source": [
        "Now We have the Dataset with the prompt and the Reference Summary, it is time to create a Dataset in LangSmith with this information.\n",
        "### Create the Dataset in Langsmith\n",
        "\n",
        "The dataset in LangSmith is composed of an input, which is the prompt passed to the model for evaluation, and an output, which should contain what we expect the model to return."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "ed9c00f6-f9ad-423f-8a8f-86fdfd30bfe0",
      "metadata": {
        "id": "ed9c00f6-f9ad-423f-8a8f-86fdfd30bfe0"
      },
      "outputs": [],
      "source": [
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "221d8e92-c2f1-499c-9e68-3abb752722c4",
      "metadata": {
        "id": "221d8e92-c2f1-499c-9e68-3abb752722c4"
      },
      "outputs": [],
      "source": [
        "#import uuid\n",
        "input_key=['article']\n",
        "output_key=['highlights']\n",
        "\n",
        "NAME_DATASET=f\"Summarize_dataset_{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "dcf23c41-e15d-4f63-bd27-233d6599e305",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c3fdaedf1abb4fb0a743d5a4c4544f29",
            "d611b68661db4633b177e31f7a8137cb",
            "894e91c90fd545769e4243eb3b940dab",
            "8f8f815c9d4e40b4864e3f5c4d4359bc",
            "c99c8a35eecc47dea9d9e033a1b58fb4",
            "c18626862dd34b70bf3e17131cf36e08",
            "f008476afcba4a67aff9970d112d3682",
            "babd7ddc60024a7390e51d6f499ad870",
            "ac22e842b2154a52b613630677457873",
            "417d5b1dbbce46a0aa455ac06aa21487",
            "03c2ad03448246b5824fec4d9004ea4c"
          ]
        },
        "id": "dcf23c41-e15d-4f63-bd27-233d6599e305",
        "outputId": "e98a0ff4-d5c1-4832-b2bf-811275e09b57"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3fdaedf1abb4fb0a743d5a4c4544f29"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#This create the Dataset in LangSmith with the content in sample_cnn\n",
        "dataset = client.upload_dataframe(\n",
        "    df=sample_cnn,\n",
        "    input_keys=input_key,\n",
        "    output_keys=output_key,\n",
        "    name=NAME_DATASET,\n",
        "    description=\"Test Embedding distance between model summarizations\",\n",
        "    data_type=\"kv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ada2bd55-b6bc-467c-b481-48d46ad50441",
      "metadata": {
        "id": "ada2bd55-b6bc-467c-b481-48d46ad50441"
      },
      "source": [
        "In this image, we can see an example from the dataset once it's been registered in LangSmith.\n",
        "\n",
        "In the Input column, there is the prompt to be sent, while in the Output column, the expected output is stored.\n",
        "\n",
        "When performing the comparison, the model will be given the prompt, and the Cosine distance between its response and the one stored in the sample dataset will be calculated.\n",
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_Dataset.jpg?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8278f53f-1a94-407c-846d-05c926737704",
      "metadata": {
        "id": "8278f53f-1a94-407c-846d-05c926737704"
      },
      "source": [
        "### Recovering Models From Hugging Face\n",
        "Let's retrieve both models from HuggingFace. A base T5 model and a model that has been fine-tuned using the training portion of this same dataset to generate summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "0f1afd20-0bbe-473b-9ad9-ebceb3519421",
      "metadata": {
        "id": "0f1afd20-0bbe-473b-9ad9-ebceb3519421"
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "5213c43f-85e2-4159-8a8e-684e79850bae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5213c43f-85e2-4159-8a8e-684e79850bae",
        "outputId": "327fd57a-d764-4af2-af86-e3212d5fd873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hugging Face Key: ··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "hf_key = getpass(\"Hugging Face Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "12339bcc-ce70-4fae-9dcb-f2f273429ed8",
      "metadata": {
        "id": "12339bcc-ce70-4fae-9dcb-f2f273429ed8"
      },
      "outputs": [],
      "source": [
        "summarizer_base = HuggingFaceHub(\n",
        "    repo_id=\"t5-base\",\n",
        "    model_kwargs={\"temperature\":0, \"max_length\":180},\n",
        "    huggingfacehub_api_token=hf_key\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "f317d1cc-95f0-4f71-9c7f-205e42afc5df",
      "metadata": {
        "id": "f317d1cc-95f0-4f71-9c7f-205e42afc5df"
      },
      "outputs": [],
      "source": [
        "summarizer_finetuned = HuggingFaceHub(\n",
        "    repo_id=\"flax-community/t5-base-cnn-dm\",\n",
        "    model_kwargs={\"temperature\":0, \"max_length\":180},\n",
        "    huggingfacehub_api_token=hf_key\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc859325-3e92-4f2b-85cc-247dd84d9cf6",
      "metadata": {
        "id": "dc859325-3e92-4f2b-85cc-247dd84d9cf6"
      },
      "source": [
        "## Defining Evaluator\n",
        "The first step is to define an evaluator, where we specify the variables we want to evaluate. In our case, I have chosen to measure only the \"embedding_distance.\"\n",
        "\n",
        "I've left the \"string_distance\" as a comment in case you want to conduct a test with two evaluations instead of one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "d506d770-2c30-41a6-acde-283ad1b27ea9",
      "metadata": {
        "id": "d506d770-2c30-41a6-acde-283ad1b27ea9"
      },
      "outputs": [],
      "source": [
        "from langchain.smith import run_on_dataset, RunEvalConfig\n",
        "!pip install -q rapidfuzz==3.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "15e8accd-d7e1-44f8-b5d0-0215ceedb88d",
      "metadata": {
        "id": "15e8accd-d7e1-44f8-b5d0-0215ceedb88d"
      },
      "outputs": [],
      "source": [
        "#We are using just one of the multiple evaluator available on LangSmith.\n",
        "evaluation_config = RunEvalConfig(\n",
        "    evaluators=[\n",
        "        \"embedding_distance\",\n",
        "        RunEvalConfig.Criteria(\"conciseness\"),\n",
        "        RunEvalConfig.Criteria(\"harmfulness\"),\n",
        "        #\"string_distance\"\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee666c30-d958-45b1-802c-7034dd13b42b",
      "metadata": {
        "id": "ee666c30-d958-45b1-802c-7034dd13b42b"
      },
      "source": [
        "## Running Evaluator\n",
        "With the same configuration, we can launch two evaluations on the same dataset. One for each of the chosen models."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_models = [summarizer_base, summarizer_finetuned]"
      ],
      "metadata": {
        "id": "EnrXICCZSVy1"
      },
      "id": "EnrXICCZSVy1",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "67c75c07-8351-465f-af15-a1abe17968f9",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67c75c07-8351-465f-af15-a1abe17968f9",
        "outputId": "a20335e0-e449-454a-ae33-979b1f8d1142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for project 'T5-BASE 2024-04-01 13:13:05' at:\n",
            "https://smith.langchain.com/o/c67fe7fc-f385-519d-9a10-9464d2be3d9d/datasets/d3aa04f3-dd67-42f3-826d-e7fc4f8873bc/compare?selectedSessions=94e02efd-a039-4290-a68b-36c94bde3eed\n",
            "\n",
            "View all tests for Dataset Summarize_dataset_2024-04-01 11:00:07 at:\n",
            "https://smith.langchain.com/o/c67fe7fc-f385-519d-9a10-9464d2be3d9d/datasets/d3aa04f3-dd67-42f3-826d-e7fc4f8873bc\n",
            "[>                                                 ] 0/3"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example c8b803f0-048e-4d91-ba53-087f685bdd5a with inputs {'article': 'Summarize this news:\\n(CNN)The attorney for a suburban New York cardiologist charged in what authorities say was a failed scheme to have another physician hurt or killed is calling the allegations against his client \"completely unsubstantiated.\" Appearing Saturday morning on CNN\\'s \"New Day,\" Randy Zelin defended his client, Dr. Anthony Moschetto, who faces criminal solicitation, conspiracy, burglary, arson, criminal prescription sale and weapons charges in connection to what prosecutors called a plot to take out a rival doctor on Long Island. \"None of anything in this case has any evidentiary value,\" Zelin told CNN\\'s Christi Paul.  \"It doesn\\'t matter what anyone says, he is presumed to be innocent.\" Moschetto,54, pleaded not guilty to all charges Wednesday.  He was released after posting $2 million bond and surrendering his passport. Zelin said that his next move is to get Dr. Moshetto back to work. \"He\\'s got patients to see. This man, while he was in a detention cell, the only thing that he cared about were his patients. And amazingly, his patients were flooding the office with calls, making sure that he was OK,\" Zelin said. Two other men -- identified as James Chmela, 43, and James Kalamaras, 41 -- were named as accomplices, according to prosecutors. They pleaded not guilty in Nassau County District Court, according to authorities. Both were released on bail. A requests for comment from an attorney representing Chmela was not returned. It\\'s unclear whether Kalamaras has retained an attorney. Police officers allegedly discovered approximately 100 weapons at Moschetto\\'s home, including hand grenades, high-capacity magazines and knives. Many of the weapons were found in a hidden room behind a switch-activated bookshelf, according to prosecutors. The investigation began back in December, when undercover officers began buying heroin and oxycodone pills from Moschetto in what was initially a routine investigation into the sale of prescription drugs, officials said. During the course of the undercover operation, however, Moschetto also sold the officers two semiautomatic assault weapons as well as ammunition, prosecutors said. Moschetto allegedly told officers during one buy that he needed dynamite to \"blow up a building.\" He later said he no longer needed the dynamite because a friend was setting fire to the building instead. Kalamaras and Chmela are believed to have taken part in the arson, according to prosecutors. \"The fire damaged but did not destroy the office of another cardiologist whose relationship with Dr. Moschetto had soured due to a professional dispute,\" according to the statement from the district attorney\\'s office. Moschetto allegedly gave an informant and undercover detective blank prescriptions and cash for the assault and killing of the fellow cardiologist, according to prosecutors. He also requested that the rival\\'s wife be assaulted if she happened to be present, authorities said. \"He was willing to pay $5,000 to have him beaten and put in a hospital for a few months, and then he said he would pay $20,000 to have him killed,\" said Assistant District Attorney Anne Donnelly, according to CNN affiliate WCBS.'}\n",
            "Error Type: HfHubHTTPError, Message: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/t5-base (Request ID: 7SBSYRVp9ctKWVVr_8WbN)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 57999dc7-18aa-44cd-9bf9-0df77ea0d30c with inputs {'article': 'Summarize this news:\\n(CNN)President Barack Obama took part in a roundtable discussion this week on climate change, refocusing on the issue from a public health vantage point. After the event at Washington\\'s Howard University on Tuesday, Obama sat down with me for a one-on-one interview. I asked him about the science behind climate change and public health and the message he wants the average American to take away, as well as how enforceable his action plan is. Here are five things I learned: . The President enrolled at Occidental College in Los Angeles in 1979 (he transferred to Columbia University his junior year). While in L.A., he said, the air was so bad that it prevented him from running outside. He remembers the air quality alerts and how people with respiratory problems had to stay inside. He credits the Clean Air Act with making Americans \"a lot\" healthier, in addition to being able to \"see the mountains in the background because they aren\\'t covered in smog.\" Obama also said the instances of asthma and other respiratory diseases went down after these measures were taken. Peer-reviewed Environmental Protection Agency studies say that the Clean Air Act and subsequent amendments have reduced early deaths associated with exposure to ambient fine particle pollution and ozone, and reduced illnesses such as chronic bronchitis and acute myocardial infarction. The EPA estimates that, between 1970 and 2010, the act and its amendments prevented 365,000 early deaths from particulate matter alone. \"No challenge poses more of a public threat than climate change,\" the President told me. When I asked about the strength of the science supporting the direct relationship between climate change and public health, he said, \"We know as temperatures rise, insect-borne diseases potentially start shifting up. We know, in a very straight-forward fashion, that heatstroke and other heat-related illnesses and deaths potentially increase, and so what we\\'re doing here is to make sure that in addition to public awareness around the potential for big storms like Hurricane Sandy or big wildfires or droughts, that people recognize there\\'s a very personal, potential impact in climate change, and the good news is we can do something about it.\" In many ways, Obama is attempting to reframe the discussion around climate change as a public health issue that affects all of us, while conceding that we don\\'t fully understand the magnitude of the correlation between rising temperatures and impact on human health. When asked what the average American can do about all this, the President encouraged ordinary citizens, doctors and nurses to start putting some pressure on elected officials \"to try and make something happen to reduce the impacts of climate change.\" He also issued a presidential proclamation declaring April 6-12 as National Public Health Week \"to better understand, communicate and reduce the health impacts of climate change on our communities.\" The average American can also do their part to reduce their own carbon footprint, including: . • Change your incandescent light bulbs to compact fluorescent lights. One CFL can reduce up to 1,300 pounds of carbon dioxide pollution during its lifetime. If every house in the U.S. switched its bulbs, we could reduce the electricity spent on lighting by half. • Unplug your gadgets and chargers when not in use. According to the U.S. Department of Energy, this practice can save $100 a year on your energy bill. • Use a laptop instead of a desktop. Laptops are designed to be energy-efficient, because battery life is a major factor in their design. According to Energy Star, a laptop can be up to 80% more energy-efficient than a desktop. • Filter your own water. Beyond the environmental toll of plastic waste, consider just how far your water was transported before you bought it at the grocery store. • Adjust your curtains and thermostats. If you keep your house 2 degrees warmer in the summer and 2 degrees colder in the winter, you can save big bucks on your energy bill. The Department of Energy estimates you can save up to 15% on your bill by turning off your thermostat when you\\'re not at home. Obama did not appear particularly concerned about the current Supreme Court challenge to the Affordable Care Act. He  said he believes the statute is \"clear and straightforward.\" He said, \"I am not anticipating the Supreme Court would make such a bad decision.\" At issue is the 32 states that did not set up their own health care exchanges and left it to the federal government to do so. The plaintiffs in the lawsuit contend that the language of the Affordable Care Act does not allow for tax subsidies in those states (without state-based exchanges), possibly creating a situation, for example, in which people in Massachusetts would receive a tax credit, but people living in Texas would not. Obama did tell me that if the Supreme Court challenge is upheld, however, there is no Plan B. \"Millions of people would lose their health insurance. They would no longer be able to afford the health insurance that\\'s being provided out there.\" Obama went on to say, \"I think this is the last gasp of folks who have been fighting against [the Affordable Care Act] for ideological reasons.\" He told me that he \"gets letters every day from people who say, \\'you know what, the Affordable Care Act saved my life or saved my kid\\'s life because I got insurance.\\' \\'I thought I was healthy; turns out I had a tumor, but because I went and got a checkup, it was removed in time, and I\\'m now cancer-free.\\' \" He added, \"I think stories like that will be factored in when the Supreme Court takes a look at this case.\" CNN\\'s Ben Tinker contributed to this report.'}\n",
            "Error Type: HfHubHTTPError, Message: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/t5-base (Request ID: M7-ji_rqha6dobjgrOVYH)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 8e9327cf-c4d3-4ccc-a159-46d551ba4a1c with inputs {'article': 'Summarize this news:\\n(CNN)James Best, best known for his portrayal of bumbling sheriff Rosco P. Coltrane on TV\\'s \"The Dukes of Hazzard,\" died Monday after a brief illness. He was 88. Best died in hospice in Hickory, North Carolina, of complications from pneumonia, said Steve Latshaw, a longtime friend and Hollywood colleague. Although he\\'d been a busy actor for decades in theater and in Hollywood, Best didn\\'t become famous until 1979, when \"The Dukes of Hazzard\\'s\" cornpone charms began beaming into millions of American homes almost every Friday night. For seven seasons, Best\\'s Rosco P. Coltrane chased the moonshine-running Duke boys back and forth across the back roads of fictitious Hazzard County, Georgia, although his \"hot pursuit\" usually ended with him crashing his patrol car. Although Rosco was slow-witted and corrupt, Best gave him a childlike enthusiasm that got laughs and made him endearing. His character became known for his distinctive \"kew-kew-kew\" chuckle and for goofy catchphrases such as \"cuff \\'em and stuff \\'em!\" upon making an arrest. Among the most popular shows on TV in the early \\'80s, \"The Dukes of Hazzard\" ran until 1985 and spawned TV movies, an animated series and video games. Several of Best\\'s \"Hazzard\" co-stars paid tribute to the late actor on social media. \"I laughed and learned more from Jimmie in one hour than from anyone else in a whole year,\" co-star John Schneider, who played Bo Duke, said on Twitter. \"Give Uncle Jesse my love when you see him dear friend.\" \"Jimmy Best was the most constantly creative person I have ever known,\" said Ben Jones, who played mechanic Cooter on the show, in a Facebook post. \"Every minute of his long life was spent acting, writing, producing, painting, teaching, fishing, or involved in another of his life\\'s many passions.\" Born Jewel Guy on July 26, 1926, in Powderly, Kentucky, Best was orphaned at 3 and adopted by Armen and Essa Best, who renamed him James and raised him in rural Indiana. Best served in the Army during World War II before launching his acting career. In the 1950s and 1960s, he accumulated scores of credits, playing a range of colorful supporting characters in such TV shows as \"The Twilight Zone,\" \"Bonanza,\" \"The Andy Griffith Show\" and \"Gunsmoke.\" He later appeared in a handful of Burt Reynolds\\' movies, including \"Hooper\" and \"The End.\" But Best will always be best known for his \"Hazzard\" role, which lives on in reruns. \"Jimmie was my teacher, mentor, close friend and collaborator for 26 years,\" Latshaw said. \"I directed two of his feature films, including the recent \\'Return of the Killer Shrews,\\' a sequel he co-wrote and was quite proud of as he had made the first one more than 50 years earlier.\" People we\\'ve lost in 2015 . CNN\\'s Stella Chan contributed to this story.'}\n",
            "Error Type: HfHubHTTPError, Message: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/t5-base (Request ID: Ampq-o5P5Qi43WQLWx1Ld)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[---------------->                                 ] 1/3\r[-------------------------------->                 ] 2/3\r[------------------------------------------------->] 3/3"
          ]
        }
      ],
      "source": [
        "project_name = f\"T5-BASE {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "base_t5_results = run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=NAME_DATASET,\n",
        "    llm_or_chain_factory=summarizer_base,\n",
        "    evaluation=evaluation_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "76ede4d6-ed51-4745-b91a-d9ec6c40d436",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76ede4d6-ed51-4745-b91a-d9ec6c40d436",
        "outputId": "a4fb69b2-e7c7-4904-e2f4-4aa7d90818bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for project 'T5-FineTuned 2024-03-31 21:32:12' at:\n",
            "https://smith.langchain.com/o/c67fe7fc-f385-519d-9a10-9464d2be3d9d/datasets/862d65ef-d665-40e5-80d0-fad40d2a1ff6/compare?selectedSessions=7d778116-8a99-46d9-96f8-d205f8e6cecb\n",
            "\n",
            "View all tests for Dataset Summarize_dataset_2024-03-31 21:31:04 at:\n",
            "https://smith.langchain.com/o/c67fe7fc-f385-519d-9a10-9464d2be3d9d/datasets/862d65ef-d665-40e5-80d0-fad40d2a1ff6\n",
            "[------------------------------------------------->] 3/3"
          ]
        }
      ],
      "source": [
        "project_name = f\"T5-FineTuned {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "finetuned_t5_results = run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=NAME_DATASET,\n",
        "    llm_or_chain_factory=summarizer_finetuned,\n",
        "    evaluation=evaluation_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "953211fe-b8a4-4a2c-91e3-3c6242a2f159",
      "metadata": {
        "id": "953211fe-b8a4-4a2c-91e3-3c6242a2f159"
      },
      "source": [
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_Tests.jpg?raw=true\">\n",
        "\n",
        "In the image below you can see the comparision between two tests.\n",
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_CompareTestst.jpg?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, since it has been so straightforward, why don't we try to make the comparison with an OpenAI model?"
      ],
      "metadata": {
        "id": "Xn6jeX7u_4MR"
      },
      "id": "Xn6jeX7u_4MR"
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OPENAI API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "z4sYgAASO7_k",
        "outputId": "26e50eb2-91d9-4c1e-985f-b48477f4c839"
      },
      "id": "z4sYgAASO7_k",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-4cdf2a0ea10a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI API Key: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    832\u001b[0m             warnings.warn(\"The `stream` parameter of `getpass.getpass` will have no effect when using ipykernel\",\n\u001b[1;32m    833\u001b[0m                     UserWarning, stacklevel=2)\n\u001b[0;32m--> 834\u001b[0;31m         return self._input_request(prompt,\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84a97ac1-623e-4d28-a78b-c807af89c918",
      "metadata": {
        "id": "84a97ac1-623e-4d28-a78b-c807af89c918"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "open_aillm=OpenAI(temperature=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_name = f\"OpenAI {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "finetuned_t5_results = run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=NAME_DATASET,\n",
        "    llm_or_chain_factory=open_aillm,\n",
        "    evaluation=evaluation_config,\n",
        ")"
      ],
      "metadata": {
        "id": "suc0G-9W94Qj"
      },
      "id": "suc0G-9W94Qj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_CompareOpenAI_HF.jpg?raw=true\">"
      ],
      "metadata": {
        "id": "B15V_-3pBvOK"
      },
      "id": "B15V_-3pBvOK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The experiment with the OpenAI model has yielded the best results. But, be aware! As we can see, there is a cost involved since we are using an API, and it needs to be paid for.\n",
        "\n",
        "Another crucial piece of information is that we can view performance data for the models. This data could also be useful for minimally evaluating our inference server."
      ],
      "metadata": {
        "id": "fUeZWvLMCOBw"
      },
      "id": "fUeZWvLMCOBw"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3fdaedf1abb4fb0a743d5a4c4544f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d611b68661db4633b177e31f7a8137cb",
              "IPY_MODEL_894e91c90fd545769e4243eb3b940dab",
              "IPY_MODEL_8f8f815c9d4e40b4864e3f5c4d4359bc"
            ],
            "layout": "IPY_MODEL_c99c8a35eecc47dea9d9e033a1b58fb4"
          }
        },
        "d611b68661db4633b177e31f7a8137cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c18626862dd34b70bf3e17131cf36e08",
            "placeholder": "​",
            "style": "IPY_MODEL_f008476afcba4a67aff9970d112d3682",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "894e91c90fd545769e4243eb3b940dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_babd7ddc60024a7390e51d6f499ad870",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac22e842b2154a52b613630677457873",
            "value": 1
          }
        },
        "8f8f815c9d4e40b4864e3f5c4d4359bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_417d5b1dbbce46a0aa455ac06aa21487",
            "placeholder": "​",
            "style": "IPY_MODEL_03c2ad03448246b5824fec4d9004ea4c",
            "value": " 1/1 [00:00&lt;00:00, 11.40ba/s]"
          }
        },
        "c99c8a35eecc47dea9d9e033a1b58fb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c18626862dd34b70bf3e17131cf36e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f008476afcba4a67aff9970d112d3682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "babd7ddc60024a7390e51d6f499ad870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac22e842b2154a52b613630677457873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "417d5b1dbbce46a0aa455ac06aa21487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03c2ad03448246b5824fec4d9004ea4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}